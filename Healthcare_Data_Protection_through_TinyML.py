# -*- coding: utf-8 -*-
"""TinyMLv2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DqF4OMS0vIJW18jBH50b0gOKq2h9Cmp7
"""

# Install necessary packages
!pip install wfdb


# Download the dataset from PhysioNet
!wget -r -N -c -np https://physionet.org/files/mitdb/1.0.0/

# Install necessary packages
!pip install wfdb
!pip install tensorflow-privacy

# Download the dataset from PhysioNet
!wget -r -N -c -np https://physionet.org/files/mitdb/1.0.0/

# Unzip the dataset (assuming itâ€™s in a zip format; adjust if it's not)
# !unzip -q mitdb.zip

import wfdb
import numpy as np
import pandas as pd
import os

# Define the directory where the dataset is stored
data_dir = '/content/physionet.org/files/mitdb/1.0.0/'

# List available files
files = os.listdir(data_dir)
print("Available files:", files)

# Function to load and preprocess data
def load_data(record_name):
    # Read the record
    record = wfdb.rdrecord(os.path.join(data_dir, record_name))
    # Convert to DataFrame
    df = pd.DataFrame(record.p_signal, columns=record.sig_name)
    # Extract signals and labels (this is an example; adapt as needed)
    signals = df.values
    labels = record.aux_note  # or use annotations if available
    return signals, labels

# Example usage
record_name = '100'  # Replace with an actual record name
signals, labels = load_data(f'{record_name}')

# Display first few rows of data
print("Signals shape:", signals.shape)
print("Labels:", labels[:5])

# Further preprocessing and model setup
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, models
from tensorflow_privacy import DPSequential
from tensorflow_privacy.dp_query import GaussianSumQuery
from tensorflow_privacy.dp_sgd import DPKerasOptimizer

# Example preprocessing
X_train, X_test, y_train, y_test = train_test_split(signals, labels, test_size=0.2, random_state=42)

# Define a TinyML model
def create_model(input_shape):
    model = models.Sequential([
        layers.Dense(64, activation='relu', input_shape=(input_shape,)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Differential Privacy Configuration
def create_dp_optimizer():
    noise_multiplier = 1.0
    l2_norm_clip = 1.0
    dp_optimizer = DPKerasOptimizer(
        l2_norm_clip=l2_norm_clip,
        noise_multiplier=noise_multiplier,
        num_microbatches=256,
        learning_rate=0.01
    )
    return dp_optimizer

# Create and compile the model with differential privacy
model = create_model(X_train.shape[1])
dp_optimizer = create_dp_optimizer()
model.compile(optimizer=dp_optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc}')

# Install necessary packages
!pip install wfdb
!pip install tensorflow

import wfdb
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow.keras import layers, models

# Define the directory where the dataset is stored
data_dir = '/content/physionet.org/files/mitdb/1.0.0/'

# List available files
files = os.listdir(data_dir)
print("Available files:", files)

# Function to load and preprocess data
def load_data(record_name):
    # Read the record
    record = wfdb.rdrecord(os.path.join(data_dir, record_name))

    # Read annotations
    ann = wfdb.rdann(os.path.join(data_dir, record_name), 'atr')

    # Convert to DataFrame
    df = pd.DataFrame(record.p_signal, columns=record.sig_name)

    # Extract signals
    signals = df.values

    # Extract annotations (labels)
    labels = ann.symbol
    times = ann.sample  # Sample times of the annotations

    # For simplicity, we assume binary classification (e.g., normal vs. abnormal)
    # You might need a more sophisticated approach depending on your use case
    binary_labels = np.zeros(len(signals))
    binary_labels[times] = 1  # Example: set annotation times as positive class

    return signals, binary_labels

# Example usage
record_name = '100'  # Replace with an actual record name
signals, labels = load_data(f'{record_name}')

# Display first few rows of data
print("Signals shape:", signals.shape)
print("Labels shape:", labels.shape)
print("Labels (sample):", labels[:5])

# Further preprocessing and model setup
from sklearn.model_selection import train_test_split

# Example preprocessing
X_train, X_test, y_train, y_test = train_test_split(signals, labels, test_size=0.2, random_state=42)

# Define a model
def create_model(input_shape):
    model = models.Sequential([
        layers.Dense(64, activation='relu', input_shape=(input_shape,)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Create and compile the model
model = create_model(X_train.shape[1])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc}')

# Install necessary packages
!pip install wfdb tensorflow

import wfdb
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

# Define the directory where the dataset is stored
data_dir = '/content/physionet.org/files/mitdb/1.0.0/'

# List available files
files = os.listdir(data_dir)
print("Available files:", files)

# Function to load and preprocess data
def load_data(record_name):
    # Read the record
    record = wfdb.rdrecord(os.path.join(data_dir, record_name))

    # Read annotations
    ann = wfdb.rdann(os.path.join(data_dir, record_name), 'atr')

    # Convert to DataFrame
    df = pd.DataFrame(record.p_signal, columns=record.sig_name)

    # Extract signals
    signals = df.values

    # Extract annotations (labels)
    labels = ann.symbol
    times = ann.sample  # Sample times of the annotations

    # For simplicity, we assume binary classification (e.g., normal vs. abnormal)
    # You might need a more sophisticated approach depending on your use case
    binary_labels = np.zeros(len(signals))
    binary_labels[times] = 1  # Example: set annotation times as positive class

    return signals, binary_labels

# Example usage
record_name = '100'  # Replace with an actual record name
signals, labels = load_data(f'{record_name}')

# Display first few rows of data
print("Signals shape:", signals.shape)
print("Labels shape:", labels.shape)
print("Labels (sample):", labels[:5])

# Further preprocessing and model setup
# Example preprocessing
X_train, X_test, y_train, y_test = train_test_split(signals, labels, test_size=0.2, random_state=42)

# Define a model
def create_model(input_shape):
    model = models.Sequential([
        layers.Dense(64, activation='relu', input_shape=(input_shape,)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')  # Ensure single output with sigmoid activation
    ])
    return model

# Create and compile the model
model = create_model(X_train.shape[1])

# Custom training loop with differential privacy
def add_noise_to_gradients(grads, noise_factor=0.1):
    noisy_grads = []
    for grad in grads:
        noisy_grad = grad + noise_factor * tf.random.normal(shape=grad.shape)
        noisy_grads.append(noisy_grad)
    return noisy_grads

optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

@tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        # Ensure predictions and labels have the same shape
        loss = tf.keras.losses.binary_crossentropy(y, predictions)
        loss = tf.reduce_mean(loss)
    grads = tape.gradient(loss, model.trainable_variables)
    noisy_grads = add_noise_to_gradients(grads, noise_factor=0.1)
    optimizer.apply_gradients(zip(noisy_grads, model.trainable_variables))
    return loss

# Compile the model manually for evaluation purposes
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
for epoch in range(5):
    for i in range(0, len(X_train), 32):
        x_batch = X_train[i:i+32]
        y_batch = y_train[i:i+32]
        y_batch = np.expand_dims(y_batch, axis=-1)  # Ensure y_batch has shape (batch_size, 1)
        loss = train_step(x_batch, y_batch)
    print(f'Epoch {epoch+1}, Loss: {loss.numpy()}')

# Evaluate the model manually
def evaluate_model(model, X_test, y_test):
    y_test = np.expand_dims(y_test, axis=-1)  # Ensure y_test has shape (num_samples, 1)
    predictions = model(X_test, training=False)
    loss = tf.keras.losses.binary_crossentropy(y_test, predictions)
    accuracy = tf.keras.metrics.binary_accuracy(y_test, predictions)
    return tf.reduce_mean(loss).numpy(), tf.reduce_mean(accuracy).numpy()

test_loss, test_acc = evaluate_model(model, X_test, y_test)
print(f'Test loss: {test_loss}')
print(f'Test accuracy: {test_acc}')

# Save the model (for TinyML deployment)
model.save('ecg_model.h5')

# Install necessary packages
!pip install wfdb tensorflow matplotlib

import wfdb
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Define the directory where the dataset is stored
data_dir = '/content/physionet.org/files/mitdb/1.0.0/'

# List available files
files = os.listdir(data_dir)
print("Available files:", files)

# Function to load and preprocess data
def load_data(record_name):
    # Read the record
    record = wfdb.rdrecord(os.path.join(data_dir, record_name))

    # Read annotations
    ann = wfdb.rdann(os.path.join(data_dir, record_name), 'atr')

    # Convert to DataFrame
    df = pd.DataFrame(record.p_signal, columns=record.sig_name)

    # Extract signals
    signals = df.values

    # Extract annotations (labels)
    labels = ann.symbol
    times = ann.sample  # Sample times of the annotations

    # For simplicity, we assume binary classification (e.g., normal vs. abnormal)
    # You might need a more sophisticated approach depending on your use case
    binary_labels = np.zeros(len(signals))
    binary_labels[times] = 1  # Example: set annotation times as positive class

    return signals, binary_labels

# Example usage
record_name = '100'  # Replace with an actual record name
signals, labels = load_data(f'{record_name}')

# Display first few rows of data
print("Signals shape:", signals.shape)
print("Labels shape:", labels.shape)
print("Labels (sample):", labels[:5])

# Further preprocessing and model setup
# Example preprocessing
X_train, X_test, y_train, y_test = train_test_split(signals, labels, test_size=0.2, random_state=42)

# Define a model
def create_model(input_shape):
    model = models.Sequential([
        layers.Dense(64, activation='relu', input_shape=(input_shape,)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')  # Ensure single output with sigmoid activation
    ])
    return model

# Create and compile the model
model = create_model(X_train.shape[1])

# Custom training loop with differential privacy
def add_noise_to_gradients(grads, noise_factor=0.1):
    noisy_grads = []
    for grad in grads:
        noisy_grad = grad + noise_factor * tf.random.normal(shape=grad.shape)
        noisy_grads.append(noisy_grad)
    return noisy_grads

optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

@tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        loss = tf.keras.losses.binary_crossentropy(y, predictions)
        loss = tf.reduce_mean(loss)
    grads = tape.gradient(loss, model.trainable_variables)
    noisy_grads = add_noise_to_gradients(grads, noise_factor=0.1)
    optimizer.apply_gradients(zip(noisy_grads, model.trainable_variables))
    return loss

# Compile the model manually for evaluation purposes
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Initialize lists to store metrics
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

# Train the model
for epoch in range(5):
    epoch_train_loss = 0
    epoch_train_accuracy = 0
    num_batches = len(X_train) // 32

    for i in range(0, len(X_train), 32):
        x_batch = X_train[i:i+32]
        y_batch = y_train[i:i+32]
        y_batch = np.expand_dims(y_batch, axis=-1)  # Ensure y_batch has shape (batch_size, 1)
        loss = train_step(x_batch, y_batch)
        epoch_train_loss += loss.numpy()

        # Calculate accuracy for the batch
        predictions = model(x_batch, training=False)
        batch_accuracy = tf.keras.metrics.binary_accuracy(y_batch, predictions)
        epoch_train_accuracy += tf.reduce_mean(batch_accuracy).numpy()

    # Average loss and accuracy over all batches
    epoch_train_loss /= num_batches
    epoch_train_accuracy /= num_batches

    # Store metrics
    train_losses.append(epoch_train_loss)
    train_accuracies.append(epoch_train_accuracy)

    # Evaluate the model on the test set
    test_loss, test_acc = evaluate_model(model, X_test, y_test)
    test_losses.append(test_loss)
    test_accuracies.append(test_acc)

    print(f'Epoch {epoch+1}, Train Loss: {epoch_train_loss}, Train Accuracy: {epoch_train_accuracy}')
    print(f'Epoch {epoch+1}, Test Loss: {test_loss}, Test Accuracy: {test_acc}')

# Plot training and testing metrics
epochs = range(1, len(train_losses) + 1)

plt.figure(figsize=(14, 6))

# Plot training and testing loss
plt.subplot(1, 2, 1)
plt.plot(epochs, train_losses, 'bo-', label='Training Loss')
plt.plot(epochs, test_losses, 'ro-', label='Testing Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Testing Loss')
plt.legend()

# Plot training and testing accuracy
plt.subplot(1, 2, 2)
plt.plot(epochs, train_accuracies, 'bo-', label='Training Accuracy')
plt.plot(epochs, test_accuracies, 'ro-', label='Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Testing Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Save the model (for TinyML deployment)
model.save('ecg_model.h5')

# Install necessary packages
!pip install wfdb tensorflow matplotlib scikit-learn xgboost seaborn

import wfdb
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier

# Define the directory where the dataset is stored
data_dir = '/content/physionet.org/files/mitdb/1.0.0/'

# List available files
files = os.listdir(data_dir)
print("Available files:", files)

# Function to load and preprocess data
def load_data(record_name):
    record = wfdb.rdrecord(os.path.join(data_dir, record_name))
    ann = wfdb.rdann(os.path.join(data_dir, record_name), 'atr')
    df = pd.DataFrame(record.p_signal, columns=record.sig_name)
    signals = df.values
    labels = ann.symbol
    times = ann.sample

    binary_labels = np.zeros(len(signals))
    binary_labels[times] = 1

    return signals, binary_labels

# Example usage
record_name = '100'  # Replace with an actual record name
signals, labels = load_data(record_name)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(signals, labels, test_size=0.2, random_state=42)

# Function to plot confusion matrix and classification report
def plot_metrics(model_name, y_test, y_pred):
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Abnormal'], yticklabels=['Normal', 'Abnormal'])
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

    print(f"Classification Report for {model_name}:")
    print(classification_report(y_test, y_pred, target_names=['Normal', 'Abnormal']))

# Initialize a dictionary to store model accuracies
model_accuracies = {}

# 1. Neural Network Model
def create_nn_model(input_shape):
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    return model

nn_model = create_nn_model(X_train.shape[1])
nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

nn_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)
y_pred_nn = (nn_model.predict(X_test) > 0.5).astype(int)
nn_accuracy = accuracy_score(y_test, y_pred_nn)
model_accuracies['Neural Network'] = nn_accuracy
plot_metrics("Neural Network", y_test, y_pred_nn)

# 2. Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)
dt_accuracy = accuracy_score(y_test, y_pred_dt)
model_accuracies['Decision Tree'] = dt_accuracy
plot_metrics("Decision Tree", y_test, y_pred_dt)

# 3. Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, y_pred_rf)
model_accuracies['Random Forest'] = rf_accuracy
plot_metrics("Random Forest", y_test, y_pred_rf)

# 4. K-Nearest Neighbors (KNN)
knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)
knn_accuracy = accuracy_score(y_test, y_pred_knn)
model_accuracies['KNN'] = knn_accuracy
plot_metrics("KNN", y_test, y_pred_knn)

# 5. XGBoost
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
model_accuracies['XGBoost'] = xgb_accuracy
plot_metrics("XGBoost", y_test, y_pred_xgb)

# Plotting model accuracies
plt.figure(figsize=(10, 5))
plt.plot(list(model_accuracies.keys()), list(model_accuracies.values()), marker='o', linestyle='-', color='b')
plt.title('Model Accuracy Comparison')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.grid(True)
plt.show()